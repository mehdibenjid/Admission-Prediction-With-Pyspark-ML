{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Spark ML\n",
    "\n",
    "**Apache Spark MLlib** is the machine learning (ML) library of **Apache Spark**, which provides high-performance, scalable, and distributed machine learning algorithms. Spark's MLlib is designed for processing large datasets using distributed computing, which makes it suitable for big data applications.\n",
    "\n",
    "Spark MLlib supports a wide range of machine learning tasks, including classification, regression, clustering, recommendation, and more. It is built on top of Sparkâ€™s powerful data processing capabilities, allowing it to handle vast amounts of data efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "## Spark ML Components\n",
    "\n",
    "Spark MLlib is structured into two main components:\n",
    "\n",
    "1. **DataFrames-based API (spark.ml)**: This is the newer, high-level API, which integrates better with Spark's DataFrame API. It is the recommended approach for most users.\n",
    "2. **RDD-based API (spark.mllib)**: This is the older API, which is based on Spark's Resilient Distributed Dataset (RDD). It is now in maintenance mode, and the DataFrames-based API is preferred.\n",
    "\n",
    "We will focus on the **DataFrames-based API (spark.ml)**.\n",
    "\n",
    "---\n",
    "\n",
    "## Features of Spark ML\n",
    "\n",
    "- **Scalability**: Spark ML is designed for distributed computing, making it highly scalable for large datasets.\n",
    "- **Ease of Use**: The DataFrame API provides an easy-to-use and intuitive interface for machine learning pipelines.\n",
    "- **Integration**: It integrates seamlessly with other components of Spark, such as SQL, streaming, and graph processing.\n",
    "- **Built-in Algorithms**: It offers a wide range of out-of-the-box algorithms for classification, regression, clustering, recommendation, and more.\n",
    "- **Pipeline Support**: Spark ML provides pipeline support for building end-to-end machine learning workflows, including data transformation, feature engineering, model training, and evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## Machine Learning Pipeline in Spark ML\n",
    "\n",
    "A machine learning pipeline in Spark ML consists of a series of **stages** that are executed in sequence to process data and train a model. The typical stages in a pipeline are:\n",
    "\n",
    "1. **Data Preparation**: Loading and cleaning data, handling missing values, and normalizing data.\n",
    "2. **Feature Engineering**: Transforming raw data into meaningful features using techniques such as one-hot encoding, vectorizing, and scaling.\n",
    "3. **Model Training**: Applying machine learning algorithms to train models.\n",
    "4. **Model Evaluation**: Evaluating the model's performance using appropriate metrics (e.g., accuracy, precision, recall).\n",
    "5. **Model Tuning**: Optimizing the model using hyperparameter tuning (e.g., cross-validation or grid search).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
      "     ---------------------------------------- 0.0/317.3 MB ? eta -:--:--\n",
      "     --------------------------------------- 1.6/317.3 MB 10.5 MB/s eta 0:00:31\n",
      "     --------------------------------------- 3.7/317.3 MB 10.9 MB/s eta 0:00:29\n",
      "      -------------------------------------- 6.8/317.3 MB 11.3 MB/s eta 0:00:28\n",
      "     - ------------------------------------- 8.7/317.3 MB 10.7 MB/s eta 0:00:29\n",
      "     - ------------------------------------ 10.5/317.3 MB 10.4 MB/s eta 0:00:30\n",
      "     - ------------------------------------ 13.1/317.3 MB 10.5 MB/s eta 0:00:29\n",
      "     - ------------------------------------ 14.9/317.3 MB 10.2 MB/s eta 0:00:30\n",
      "     -- ------------------------------------ 16.5/317.3 MB 9.9 MB/s eta 0:00:31\n",
      "     -- ------------------------------------ 18.6/317.3 MB 9.9 MB/s eta 0:00:31\n",
      "     -- ------------------------------------ 20.7/317.3 MB 9.9 MB/s eta 0:00:30\n",
      "     -- ----------------------------------- 23.3/317.3 MB 10.1 MB/s eta 0:00:30\n",
      "     --- ---------------------------------- 26.0/317.3 MB 10.3 MB/s eta 0:00:29\n",
      "     --- ---------------------------------- 28.3/317.3 MB 10.4 MB/s eta 0:00:28\n",
      "     --- ---------------------------------- 30.7/317.3 MB 10.5 MB/s eta 0:00:28\n",
      "     --- ---------------------------------- 32.5/317.3 MB 10.3 MB/s eta 0:00:28\n",
      "     ---- --------------------------------- 34.3/317.3 MB 10.2 MB/s eta 0:00:28\n",
      "     ---- --------------------------------- 36.7/317.3 MB 10.3 MB/s eta 0:00:28\n",
      "     ---- --------------------------------- 39.1/317.3 MB 10.4 MB/s eta 0:00:27\n",
      "     ---- --------------------------------- 41.4/317.3 MB 10.5 MB/s eta 0:00:27\n",
      "     ----- -------------------------------- 44.0/317.3 MB 10.5 MB/s eta 0:00:26\n",
      "     ----- -------------------------------- 46.4/317.3 MB 10.6 MB/s eta 0:00:26\n",
      "     ----- -------------------------------- 48.8/317.3 MB 10.7 MB/s eta 0:00:26\n",
      "     ------ ------------------------------- 51.1/317.3 MB 10.7 MB/s eta 0:00:25\n",
      "     ------ ------------------------------- 53.5/317.3 MB 10.7 MB/s eta 0:00:25\n",
      "     ------ ------------------------------- 55.3/317.3 MB 10.6 MB/s eta 0:00:25\n",
      "     ------ ------------------------------- 57.7/317.3 MB 10.6 MB/s eta 0:00:25\n",
      "     ------- ------------------------------ 60.3/317.3 MB 10.7 MB/s eta 0:00:24\n",
      "     ------- ------------------------------ 62.7/317.3 MB 10.8 MB/s eta 0:00:24\n",
      "     ------- ------------------------------ 65.3/317.3 MB 10.8 MB/s eta 0:00:24\n",
      "     -------- ----------------------------- 67.6/317.3 MB 10.9 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 70.0/317.3 MB 10.9 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 72.6/317.3 MB 10.9 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 75.0/317.3 MB 10.9 MB/s eta 0:00:23\n",
      "     --------- ---------------------------- 77.6/317.3 MB 10.9 MB/s eta 0:00:22\n",
      "     --------- ---------------------------- 80.0/317.3 MB 11.0 MB/s eta 0:00:22\n",
      "     --------- ---------------------------- 82.3/317.3 MB 11.0 MB/s eta 0:00:22\n",
      "     ---------- --------------------------- 84.9/317.3 MB 11.0 MB/s eta 0:00:22\n",
      "     ---------- --------------------------- 87.3/317.3 MB 11.1 MB/s eta 0:00:21\n",
      "     ---------- --------------------------- 89.9/317.3 MB 11.1 MB/s eta 0:00:21\n",
      "     ----------- -------------------------- 92.5/317.3 MB 11.1 MB/s eta 0:00:21\n",
      "     ----------- -------------------------- 94.9/317.3 MB 11.1 MB/s eta 0:00:20\n",
      "     ----------- -------------------------- 97.5/317.3 MB 11.1 MB/s eta 0:00:20\n",
      "     ----------- -------------------------- 99.4/317.3 MB 11.1 MB/s eta 0:00:20\n",
      "     ----------- ------------------------- 101.2/317.3 MB 11.0 MB/s eta 0:00:20\n",
      "     ----------- ------------------------- 102.5/317.3 MB 10.9 MB/s eta 0:00:20\n",
      "     ------------ ------------------------ 104.1/317.3 MB 10.8 MB/s eta 0:00:20\n",
      "     ------------ ------------------------ 106.4/317.3 MB 10.8 MB/s eta 0:00:20\n",
      "     ------------ ------------------------ 109.1/317.3 MB 10.9 MB/s eta 0:00:20\n",
      "     ------------- ----------------------- 111.7/317.3 MB 10.9 MB/s eta 0:00:19\n",
      "     ------------- ----------------------- 114.0/317.3 MB 10.9 MB/s eta 0:00:19\n",
      "     ------------- ----------------------- 116.1/317.3 MB 10.9 MB/s eta 0:00:19\n",
      "     ------------- ----------------------- 118.2/317.3 MB 10.9 MB/s eta 0:00:19\n",
      "     -------------- ---------------------- 120.6/317.3 MB 10.9 MB/s eta 0:00:19\n",
      "     -------------- ---------------------- 123.2/317.3 MB 10.9 MB/s eta 0:00:18\n",
      "     -------------- ---------------------- 125.8/317.3 MB 10.9 MB/s eta 0:00:18\n",
      "     -------------- ---------------------- 128.5/317.3 MB 11.0 MB/s eta 0:00:18\n",
      "     --------------- --------------------- 130.8/317.3 MB 11.0 MB/s eta 0:00:18\n",
      "     --------------- --------------------- 133.2/317.3 MB 11.0 MB/s eta 0:00:17\n",
      "     --------------- --------------------- 135.3/317.3 MB 11.0 MB/s eta 0:00:17\n",
      "     ---------------- -------------------- 137.6/317.3 MB 11.0 MB/s eta 0:00:17\n",
      "     ---------------- -------------------- 140.0/317.3 MB 11.0 MB/s eta 0:00:17\n",
      "     ---------------- -------------------- 142.6/317.3 MB 11.0 MB/s eta 0:00:16\n",
      "     ---------------- -------------------- 145.0/317.3 MB 11.0 MB/s eta 0:00:16\n",
      "     ----------------- ------------------- 147.6/317.3 MB 11.0 MB/s eta 0:00:16\n",
      "     ----------------- ------------------- 148.9/317.3 MB 11.0 MB/s eta 0:00:16\n",
      "     ----------------- ------------------- 151.0/317.3 MB 10.9 MB/s eta 0:00:16\n",
      "     ----------------- ------------------- 153.4/317.3 MB 11.0 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 155.7/317.3 MB 11.0 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 157.8/317.3 MB 10.9 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 160.4/317.3 MB 11.0 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 162.8/317.3 MB 11.0 MB/s eta 0:00:15\n",
      "     ------------------- ----------------- 165.4/317.3 MB 11.0 MB/s eta 0:00:14\n",
      "     ------------------- ----------------- 168.0/317.3 MB 11.0 MB/s eta 0:00:14\n",
      "     ------------------- ----------------- 170.4/317.3 MB 11.0 MB/s eta 0:00:14\n",
      "     -------------------- ---------------- 173.0/317.3 MB 11.0 MB/s eta 0:00:14\n",
      "     -------------------- ---------------- 175.6/317.3 MB 11.0 MB/s eta 0:00:13\n",
      "     -------------------- ---------------- 178.3/317.3 MB 11.0 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 180.6/317.3 MB 11.0 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 182.5/317.3 MB 11.0 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 183.8/317.3 MB 11.0 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 185.1/317.3 MB 10.9 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 186.1/317.3 MB 10.8 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 187.7/317.3 MB 10.8 MB/s eta 0:00:13\n",
      "     ---------------------- -------------- 189.3/317.3 MB 10.7 MB/s eta 0:00:12\n",
      "     ---------------------- -------------- 190.8/317.3 MB 10.7 MB/s eta 0:00:12\n",
      "     ---------------------- -------------- 192.9/317.3 MB 10.7 MB/s eta 0:00:12\n",
      "     ---------------------- -------------- 194.8/317.3 MB 10.7 MB/s eta 0:00:12\n",
      "     ---------------------- -------------- 196.1/317.3 MB 10.6 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 198.2/317.3 MB 10.6 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 200.5/317.3 MB 10.6 MB/s eta 0:00:11\n",
      "     ----------------------- ------------- 202.9/317.3 MB 10.6 MB/s eta 0:00:11\n",
      "     ----------------------- ------------- 205.5/317.3 MB 10.7 MB/s eta 0:00:11\n",
      "     ------------------------ ------------ 208.1/317.3 MB 10.7 MB/s eta 0:00:11\n",
      "     ------------------------ ------------ 210.8/317.3 MB 10.7 MB/s eta 0:00:10\n",
      "     ------------------------ ------------ 213.1/317.3 MB 10.7 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 215.7/317.3 MB 10.7 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 218.1/317.3 MB 10.7 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 220.2/317.3 MB 10.7 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 222.8/317.3 MB 10.7 MB/s eta 0:00:09\n",
      "     -------------------------- ---------- 224.9/317.3 MB 10.7 MB/s eta 0:00:09\n",
      "     -------------------------- ---------- 227.8/317.3 MB 10.8 MB/s eta 0:00:09\n",
      "     -------------------------- ---------- 230.2/317.3 MB 10.8 MB/s eta 0:00:09\n",
      "     --------------------------- --------- 232.5/317.3 MB 10.8 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 234.6/317.3 MB 10.8 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 237.2/317.3 MB 10.8 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 239.3/317.3 MB 10.8 MB/s eta 0:00:08\n",
      "     ---------------------------- -------- 240.9/317.3 MB 10.8 MB/s eta 0:00:08\n",
      "     ---------------------------- -------- 243.5/317.3 MB 10.8 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 246.2/317.3 MB 10.8 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 248.5/317.3 MB 10.8 MB/s eta 0:00:07\n",
      "     ----------------------------- ------- 251.1/317.3 MB 10.8 MB/s eta 0:00:07\n",
      "     ----------------------------- ------- 253.8/317.3 MB 10.8 MB/s eta 0:00:06\n",
      "     ----------------------------- ------- 256.4/317.3 MB 10.8 MB/s eta 0:00:06\n",
      "     ------------------------------ ------ 258.7/317.3 MB 10.8 MB/s eta 0:00:06\n",
      "     ------------------------------ ------ 261.1/317.3 MB 10.8 MB/s eta 0:00:06\n",
      "     ------------------------------ ------ 263.7/317.3 MB 10.9 MB/s eta 0:00:05\n",
      "     ------------------------------- ----- 266.1/317.3 MB 10.9 MB/s eta 0:00:05\n",
      "     ------------------------------- ----- 268.7/317.3 MB 10.9 MB/s eta 0:00:05\n",
      "     ------------------------------- ----- 270.8/317.3 MB 10.9 MB/s eta 0:00:05\n",
      "     ------------------------------- ----- 273.2/317.3 MB 10.9 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 275.5/317.3 MB 10.9 MB/s eta 0:00:04\n",
      "     -------------------------------- ---- 277.9/317.3 MB 10.9 MB/s eta 0:00:04\n",
      "     -------------------------------- ---- 280.5/317.3 MB 11.0 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 283.1/317.3 MB 11.0 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 285.5/317.3 MB 11.0 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 288.1/317.3 MB 11.0 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 290.5/317.3 MB 11.0 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 293.1/317.3 MB 11.0 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 295.7/317.3 MB 11.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 298.1/317.3 MB 11.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 300.4/317.3 MB 11.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 303.0/317.3 MB 11.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 305.4/317.3 MB 11.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 308.0/317.3 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  310.1/317.3 MB 11.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  312.5/317.3 MB 11.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  312.7/317.3 MB 11.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  313.5/317.3 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  314.0/317.3 MB 10.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  314.3/317.3 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  314.8/317.3 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  315.4/317.3 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  316.1/317.3 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  316.9/317.3 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.3 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.3 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.3 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.3 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.3 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- 317.3/317.3 MB 10.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840668 sha256=381c87f9607e69fe1b7c18ede92041aa8bdce1dc795503c292e314d0a51acfe0\n",
      "  Stored in directory: c:\\users\\mehdi\\appdata\\local\\pip\\cache\\wheels\\07\\a0\\a3\\d24c94bf043ab5c7e38c30491199a2a11fef8d2584e6df7fb7\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.3\n"
     ]
    }
   ],
   "source": [
    "# Install Pyspark\n",
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'admission_dataset'...\n"
     ]
    }
   ],
   "source": [
    "# Clone the dataset\n",
    "! git clone https://github.com/education454/admission_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Mehdi\\\\Desktop\\\\Admission-Prediction-With-Pyspark-ML'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.listdir('admission_dataset')\n",
    "cwd = os.getcwd()\n",
    "cwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark dataframe\n",
    "df = spark.read.csv('admission_dataset/Admission_Predict_Ver1.1.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
      "|Serial No|GRE Score|TOEFL Score|University Rating|SOP|LOR|CGPA|Research|Chance of Admit|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
      "|        1|      337|        118|                4|4.5|4.5|9.65|       1|           0.92|\n",
      "|        2|      324|        107|                4|4.0|4.5|8.87|       1|           0.76|\n",
      "|        3|      316|        104|                3|3.0|3.5| 8.0|       1|           0.72|\n",
      "|        4|      322|        110|                3|3.5|2.5|8.67|       1|            0.8|\n",
      "|        5|      314|        103|                2|2.0|3.0|8.21|       0|           0.65|\n",
      "|        6|      330|        115|                5|4.5|3.0|9.34|       1|            0.9|\n",
      "|        7|      321|        109|                3|3.0|4.0| 8.2|       1|           0.75|\n",
      "|        8|      308|        101|                2|3.0|4.0| 7.9|       0|           0.68|\n",
      "|        9|      302|        102|                1|2.0|1.5| 8.0|       0|            0.5|\n",
      "|       10|      323|        108|                3|3.5|3.0| 8.6|       0|           0.45|\n",
      "|       11|      325|        106|                3|3.5|4.0| 8.4|       1|           0.52|\n",
      "|       12|      327|        111|                4|4.0|4.5| 9.0|       1|           0.84|\n",
      "|       13|      328|        112|                4|4.0|4.5| 9.1|       1|           0.78|\n",
      "|       14|      307|        109|                3|4.0|3.0| 8.0|       1|           0.62|\n",
      "|       15|      311|        104|                3|3.5|2.0| 8.2|       1|           0.61|\n",
      "|       16|      314|        105|                3|3.5|2.5| 8.3|       0|           0.54|\n",
      "|       17|      317|        107|                3|4.0|3.0| 8.7|       0|           0.66|\n",
      "|       18|      319|        106|                3|4.0|3.0| 8.0|       1|           0.65|\n",
      "|       19|      318|        110|                3|4.0|3.0| 8.8|       0|           0.63|\n",
      "|       20|      303|        102|                3|3.5|3.0| 8.5|       0|           0.62|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 9)\n"
     ]
    }
   ],
   "source": [
    "#get the number of rows and columns\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Serial No: integer (nullable = true)\n",
      " |-- GRE Score: integer (nullable = true)\n",
      " |-- TOEFL Score: integer (nullable = true)\n",
      " |-- University Rating: integer (nullable = true)\n",
      " |-- SOP: double (nullable = true)\n",
      " |-- LOR: double (nullable = true)\n",
      " |-- CGPA: double (nullable = true)\n",
      " |-- Research: integer (nullable = true)\n",
      " |-- Chance of Admit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|        Serial No|         GRE Score|      TOEFL Score|University Rating|               SOP|               LOR|              CGPA|          Research|    Chance of Admit|\n",
      "+-------+-----------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|              500|               500|              500|              500|               500|               500|               500|               500|                500|\n",
      "|   mean|            250.5|           316.472|          107.192|            3.114|             3.374|             3.484| 8.576440000000003|              0.56| 0.7217399999999996|\n",
      "| stddev|144.4818327679989|11.295148372354712|6.081867659564538|1.143511800759815|0.9910036207566072|0.9254495738978191|0.6048128003332054|0.4968840786090358|0.14114040395030228|\n",
      "|    min|                1|               290|               92|                1|               1.0|               1.0|               6.8|                 0|               0.34|\n",
      "|    max|              500|               340|              120|                5|               5.0|               5.0|              9.92|                 1|               0.97|\n",
      "+-------+-----------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the summary statistics\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the unnecessary columns\n",
    "df = df.drop('Serial No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
      "|Serial No|GRE Score|TOEFL Score|University Rating|SOP|LOR|CGPA|Research|Chance of Admit|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
      "|        1|      337|        118|                4|4.5|4.5|9.65|       1|           0.92|\n",
      "|        2|      324|        107|                4|4.0|4.5|8.87|       1|           0.76|\n",
      "|        3|      316|        104|                3|3.0|3.5| 8.0|       1|           0.72|\n",
      "|        4|      322|        110|                3|3.5|2.5|8.67|       1|            0.8|\n",
      "|        5|      314|        103|                2|2.0|3.0|8.21|       0|           0.65|\n",
      "|        6|      330|        115|                5|4.5|3.0|9.34|       1|            0.9|\n",
      "|        7|      321|        109|                3|3.0|4.0| 8.2|       1|           0.75|\n",
      "|        8|      308|        101|                2|3.0|4.0| 7.9|       0|           0.68|\n",
      "|        9|      302|        102|                1|2.0|1.5| 8.0|       0|            0.5|\n",
      "|       10|      323|        108|                3|3.5|3.0| 8.6|       0|           0.45|\n",
      "|       11|      325|        106|                3|3.5|4.0| 8.4|       1|           0.52|\n",
      "|       12|      327|        111|                4|4.0|4.5| 9.0|       1|           0.84|\n",
      "|       13|      328|        112|                4|4.0|4.5| 9.1|       1|           0.78|\n",
      "|       14|      307|        109|                3|4.0|3.0| 8.0|       1|           0.62|\n",
      "|       15|      311|        104|                3|3.5|2.0| 8.2|       1|           0.61|\n",
      "|       16|      314|        105|                3|3.5|2.5| 8.3|       0|           0.54|\n",
      "|       17|      317|        107|                3|4.0|3.0| 8.7|       0|           0.66|\n",
      "|       18|      319|        106|                3|4.0|3.0| 8.0|       1|           0.65|\n",
      "|       19|      318|        110|                3|4.0|3.0| 8.8|       0|           0.63|\n",
      "|       20|      303|        102|                3|3.5|3.0| 8.5|       0|           0.62|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
      "|Serial No|GRE Score|TOEFL Score|University Rating|SOP|LOR|CGPA|Research|Chance of Admit|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
      "|        0|        0|          0|                0|  0|  0|   0|       0|              0|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation to Chance of Admit for Serial No 0.00850504936113174\n",
      "Correlation to Chance of Admit for GRE Score 0.8103506354632598\n",
      "Correlation to Chance of Admit for TOEFL Score 0.7922276143050823\n",
      "Correlation to Chance of Admit for University Rating 0.6901323687886892\n",
      "Correlation to Chance of Admit for SOP 0.6841365241316723\n",
      "Correlation to Chance of Admit for LOR 0.6453645135280112\n",
      "Correlation to Chance of Admit for CGPA 0.882412574904574\n",
      "Correlation to Chance of Admit for Research 0.5458710294711379\n",
      "Correlation to Chance of Admit for Chance of Admit 1.0\n"
     ]
    }
   ],
   "source": [
    "# correlation analysis\n",
    "from pyspark.sql.functions import corr\n",
    "\n",
    "for col in df.columns:\n",
    "    print('Correlation to Chance of Admit for', col, df.stat.corr('Chance of Admit', col))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+------------------+\n",
      "|Serial No|GRE Score|TOEFL Score|University Rating|SOP|LOR|CGPA|Research|Chance of Admit|          features|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+------------------+\n",
      "|        1|      337|        118|                4|4.5|4.5|9.65|       1|           0.92|[337.0,118.0,9.65]|\n",
      "|        2|      324|        107|                4|4.0|4.5|8.87|       1|           0.76|[324.0,107.0,8.87]|\n",
      "|        3|      316|        104|                3|3.0|3.5| 8.0|       1|           0.72| [316.0,104.0,8.0]|\n",
      "|        4|      322|        110|                3|3.5|2.5|8.67|       1|            0.8|[322.0,110.0,8.67]|\n",
      "|        5|      314|        103|                2|2.0|3.0|8.21|       0|           0.65|[314.0,103.0,8.21]|\n",
      "|        6|      330|        115|                5|4.5|3.0|9.34|       1|            0.9|[330.0,115.0,9.34]|\n",
      "|        7|      321|        109|                3|3.0|4.0| 8.2|       1|           0.75| [321.0,109.0,8.2]|\n",
      "|        8|      308|        101|                2|3.0|4.0| 7.9|       0|           0.68| [308.0,101.0,7.9]|\n",
      "|        9|      302|        102|                1|2.0|1.5| 8.0|       0|            0.5| [302.0,102.0,8.0]|\n",
      "|       10|      323|        108|                3|3.5|3.0| 8.6|       0|           0.45| [323.0,108.0,8.6]|\n",
      "|       11|      325|        106|                3|3.5|4.0| 8.4|       1|           0.52| [325.0,106.0,8.4]|\n",
      "|       12|      327|        111|                4|4.0|4.5| 9.0|       1|           0.84| [327.0,111.0,9.0]|\n",
      "|       13|      328|        112|                4|4.0|4.5| 9.1|       1|           0.78| [328.0,112.0,9.1]|\n",
      "|       14|      307|        109|                3|4.0|3.0| 8.0|       1|           0.62| [307.0,109.0,8.0]|\n",
      "|       15|      311|        104|                3|3.5|2.0| 8.2|       1|           0.61| [311.0,104.0,8.2]|\n",
      "|       16|      314|        105|                3|3.5|2.5| 8.3|       0|           0.54| [314.0,105.0,8.3]|\n",
      "|       17|      317|        107|                3|4.0|3.0| 8.7|       0|           0.66| [317.0,107.0,8.7]|\n",
      "|       18|      319|        106|                3|4.0|3.0| 8.0|       1|           0.65| [319.0,106.0,8.0]|\n",
      "|       19|      318|        110|                3|4.0|3.0| 8.8|       0|           0.63| [318.0,110.0,8.8]|\n",
      "|       20|      303|        102|                3|3.5|3.0| 8.5|       0|           0.62| [303.0,102.0,8.5]|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['GRE Score', 'TOEFL Score', 'CGPA'], outputCol='features')\n",
    "output_data = assembler.transform(df)\n",
    "output_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+\n",
      "|          features|Chance of Admit|\n",
      "+------------------+---------------+\n",
      "|[337.0,118.0,9.65]|           0.92|\n",
      "|[324.0,107.0,8.87]|           0.76|\n",
      "| [316.0,104.0,8.0]|           0.72|\n",
      "|[322.0,110.0,8.67]|            0.8|\n",
      "|[314.0,103.0,8.21]|           0.65|\n",
      "|[330.0,115.0,9.34]|            0.9|\n",
      "| [321.0,109.0,8.2]|           0.75|\n",
      "| [308.0,101.0,7.9]|           0.68|\n",
      "| [302.0,102.0,8.0]|            0.5|\n",
      "| [323.0,108.0,8.6]|           0.45|\n",
      "| [325.0,106.0,8.4]|           0.52|\n",
      "| [327.0,111.0,9.0]|           0.84|\n",
      "| [328.0,112.0,9.1]|           0.78|\n",
      "| [307.0,109.0,8.0]|           0.62|\n",
      "| [311.0,104.0,8.2]|           0.61|\n",
      "| [314.0,105.0,8.3]|           0.54|\n",
      "| [317.0,107.0,8.7]|           0.66|\n",
      "| [319.0,106.0,8.0]|           0.65|\n",
      "| [318.0,110.0,8.8]|           0.63|\n",
      "| [303.0,102.0,8.5]|           0.62|\n",
      "+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import LinearRegression and create findal data\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "final_data = output_data.select('features', 'Chance of Admit')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Chance of Admit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the final data\n",
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing data\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the linear regression model\n",
    "lr = LinearRegression(featuresCol='features' ,labelCol='Chance of Admit')\n",
    "model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0024357089411697662,0.003274343953603397,0.13880979615213976]\n",
      "Intercept: -1.5886664006130302\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients and intercept\n",
    "print('Coefficients: {}'.format(model.coefficients))\n",
    "print('Intercept: {}'.format(model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.05967141273543487\n",
      "R2: 0.8176572801166437\n"
     ]
    }
   ],
   "source": [
    "# get summary of the model\n",
    "training_summary = model.summary\n",
    "print('RMSE: {}'.format(training_summary.rootMeanSquaredError))\n",
    "print('R2: {}'.format(training_summary.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+-------------------+\n",
      "|          features|Chance of Admit|         prediction|\n",
      "+------------------+---------------+-------------------+\n",
      "|[290.0,100.0,7.56]|           0.47|0.49452564659671827|\n",
      "|[290.0,104.0,7.46]|           0.45|0.49374204279591805|\n",
      "| [294.0,93.0,7.36]|           0.46|0.45358611545574545|\n",
      "|[295.0,101.0,7.86]|           0.69| 0.5516214741018124|\n",
      "| [296.0,95.0,7.54]|           0.44|  0.489991984552677|\n",
      "| [297.0,96.0,7.89]|           0.43| 0.5442854661006993|\n",
      "| [298.0,92.0,7.88]|           0.51| 0.5322357012659338|\n",
      "| [298.0,97.0,7.21]|           0.45| 0.4556048576120171|\n",
      "|  [298.0,99.0,7.6]|           0.46| 0.5162893660185586|\n",
      "|[298.0,101.0,7.86]|           0.54| 0.5589286009253218|\n",
      "| [299.0,94.0,7.34]|           0.42|0.46626280819215493|\n",
      "|[299.0,100.0,7.88]|           0.68| 0.5608661618359307|\n",
      "|[299.0,100.0,7.89]|           0.59| 0.5622542597974522|\n",
      "|[299.0,100.0,8.02]|           0.63| 0.5802995332972305|\n",
      "|[299.0,102.0,8.62]|           0.56|  0.670134098895721|\n",
      "| [300.0,95.0,8.22]|           0.62| 0.5941254817008113|\n",
      "|  [300.0,97.0,8.1]|           0.65| 0.5840169940697613|\n",
      "| [300.0,98.0,8.02]|           0.61| 0.5761865543311933|\n",
      "|[300.0,102.0,8.17]|           0.63|  0.610105399568428|\n",
      "| [301.0,96.0,7.56]|           0.54| 0.5082210691351721|\n",
      "+------------------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the predictions\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.06755054685537806\n",
      "R2: 0.7741648382556023\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol='Chance of Admit', predictionCol='prediction', metricName='rmse')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "r2 = evaluator.evaluate(predictions, {evaluator.metricName: 'r2'})\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('R2: {}'.format(r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+--------------------+\n",
      "|Serial No|GRE Score|TOEFL Score|University Rating|SOP|LOR|CGPA|Research|Chance of Admit|            features|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+--------------------+\n",
      "|        1|      337|        118|                4|4.5|4.5|9.65|       1|           0.92|[337.0,118.0,9.65...|\n",
      "|        2|      324|        107|                4|4.0|4.5|8.87|       1|           0.76|[324.0,107.0,8.87...|\n",
      "|        3|      316|        104|                3|3.0|3.5| 8.0|       1|           0.72|[316.0,104.0,8.0,...|\n",
      "|        4|      322|        110|                3|3.5|2.5|8.67|       1|            0.8|[322.0,110.0,8.67...|\n",
      "|        5|      314|        103|                2|2.0|3.0|8.21|       0|           0.65|[314.0,103.0,8.21...|\n",
      "|        6|      330|        115|                5|4.5|3.0|9.34|       1|            0.9|[330.0,115.0,9.34...|\n",
      "|        7|      321|        109|                3|3.0|4.0| 8.2|       1|           0.75|[321.0,109.0,8.2,...|\n",
      "|        8|      308|        101|                2|3.0|4.0| 7.9|       0|           0.68|[308.0,101.0,7.9,...|\n",
      "|        9|      302|        102|                1|2.0|1.5| 8.0|       0|            0.5|[302.0,102.0,8.0,...|\n",
      "|       10|      323|        108|                3|3.5|3.0| 8.6|       0|           0.45|[323.0,108.0,8.6,...|\n",
      "|       11|      325|        106|                3|3.5|4.0| 8.4|       1|           0.52|[325.0,106.0,8.4,...|\n",
      "|       12|      327|        111|                4|4.0|4.5| 9.0|       1|           0.84|[327.0,111.0,9.0,...|\n",
      "|       13|      328|        112|                4|4.0|4.5| 9.1|       1|           0.78|[328.0,112.0,9.1,...|\n",
      "|       14|      307|        109|                3|4.0|3.0| 8.0|       1|           0.62|[307.0,109.0,8.0,...|\n",
      "|       15|      311|        104|                3|3.5|2.0| 8.2|       1|           0.61|[311.0,104.0,8.2,...|\n",
      "|       16|      314|        105|                3|3.5|2.5| 8.3|       0|           0.54|[314.0,105.0,8.3,...|\n",
      "|       17|      317|        107|                3|4.0|3.0| 8.7|       0|           0.66|[317.0,107.0,8.7,...|\n",
      "|       18|      319|        106|                3|4.0|3.0| 8.0|       1|           0.65|[319.0,106.0,8.0,...|\n",
      "|       19|      318|        110|                3|4.0|3.0| 8.8|       0|           0.63|[318.0,110.0,8.8,...|\n",
      "|       20|      303|        102|                3|3.5|3.0| 8.5|       0|           0.62|[303.0,102.0,8.5,...|\n",
      "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+---------------+--------------------+\n",
      "|            features|Chance of Admit|      scaledFeatures|\n",
      "+--------------------+---------------+--------------------+\n",
      "|[337.0,118.0,9.65...|           0.92|[0.94000000000000...|\n",
      "|[324.0,107.0,8.87...|           0.76|[0.68,0.535714285...|\n",
      "|[316.0,104.0,8.0,...|           0.72|[0.52,0.428571428...|\n",
      "|[322.0,110.0,8.67...|            0.8|[0.64,0.642857142...|\n",
      "|[314.0,103.0,8.21...|           0.65|[0.48,0.392857142...|\n",
      "|[330.0,115.0,9.34...|            0.9|[0.8,0.8214285714...|\n",
      "|[321.0,109.0,8.2,...|           0.75|[0.62,0.607142857...|\n",
      "|[308.0,101.0,7.9,...|           0.68|[0.36,0.321428571...|\n",
      "|[302.0,102.0,8.0,...|            0.5|[0.24,0.357142857...|\n",
      "|[323.0,108.0,8.6,...|           0.45|[0.66,0.571428571...|\n",
      "|[325.0,106.0,8.4,...|           0.52|[0.70000000000000...|\n",
      "|[327.0,111.0,9.0,...|           0.84|[0.74,0.678571428...|\n",
      "|[328.0,112.0,9.1,...|           0.78|[0.76,0.714285714...|\n",
      "|[307.0,109.0,8.0,...|           0.62|[0.34,0.607142857...|\n",
      "|[311.0,104.0,8.2,...|           0.61|[0.42,0.428571428...|\n",
      "|[314.0,105.0,8.3,...|           0.54|[0.48,0.464285714...|\n",
      "|[317.0,107.0,8.7,...|           0.66|[0.54,0.535714285...|\n",
      "|[319.0,106.0,8.0,...|           0.65|[0.58,0.5,0.38461...|\n",
      "|[318.0,110.0,8.8,...|           0.63|[0.56,0.642857142...|\n",
      "|[303.0,102.0,8.5,...|           0.62|[0.26,0.357142857...|\n",
      "+--------------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Coefficients: [0.1253717877173198,0.07239884528191504,0.40229676534230874,0.046473510236109974]\n",
      "Intercept: 0.36274421553376957\n",
      "RMSE: 0.0600115854728031\n",
      "R2: 0.8113322025403243\n",
      "+--------------------+---------------+--------------------+-------------------+\n",
      "|            features|Chance of Admit|      scaledFeatures|         prediction|\n",
      "+--------------------+---------------+--------------------+-------------------+\n",
      "|[290.0,100.0,7.56...|           0.47|[0.0,0.2857142857...| 0.4814249658167472|\n",
      "|[294.0,93.0,7.36,...|           0.46|[0.08,0.035714285...| 0.4475667433250446|\n",
      "|[294.0,95.0,7.64,...|           0.49|[0.08,0.107142857...| 0.4888416452806632|\n",
      "|[295.0,96.0,7.34,...|           0.47|[0.1,0.1428571428...| 0.4668707503569055|\n",
      "|[295.0,99.0,7.57,...|           0.37|[0.1,0.25,0.24679...| 0.4926658842521271|\n",
      "|[295.0,101.0,7.86...|           0.69|[0.1,0.3214285714...| 0.5468485764762038|\n",
      "|[297.0,96.0,7.89,...|           0.43|[0.14,0.142857142...| 0.5428033208842745|\n",
      "|[297.0,100.0,7.9,...|           0.52|[0.14,0.285714285...| 0.5428170482178083|\n",
      "|[298.0,97.0,7.21,...|           0.45|[0.16,0.178571428...|0.46021636544313116|\n",
      "|[298.0,99.0,7.6,2.0]|           0.46|[0.16,0.25,0.2564...|  0.515674807202485|\n",
      "|[298.0,101.0,7.86...|           0.54|[0.16,0.321428571...| 0.5543708837392429|\n",
      "|[299.0,100.0,7.42...|           0.42|[0.18,0.285714285...| 0.5091768647918931|\n",
      "|[300.0,95.0,8.22,...|           0.62|[0.2,0.1071428571...| 0.5902905745127369|\n",
      "|[300.0,99.0,6.8,1.0]|           0.36|  [0.2,0.25,0.0,0.0]|0.40591828439771227|\n",
      "|[300.0,102.0,7.87...|           0.56|[0.2,0.3571428571...| 0.5632608410031489|\n",
      "|[300.0,102.0,8.17...|           0.63|[0.2,0.3571428571...| 0.6135615998450906|\n",
      "|[300.0,104.0,8.16...|           0.71|[0.2,0.4285714285...| 0.6174435332272256|\n",
      "|[301.0,97.0,7.88,...|           0.44|[0.22,0.178571428...| 0.5541293242380123|\n",
      "|[301.0,98.0,8.03,...|           0.67|[0.22,0.214285714...| 0.5644378103662245|\n",
      "|[302.0,99.0,7.97,...|           0.56|[0.24,0.25,0.3749...| 0.5734128204687983|\n",
      "+--------------------+---------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scale the features \n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "scaler = MinMaxScaler(inputCol='features', outputCol='scaledFeatures')\n",
    "assembler = VectorAssembler(inputCols=['GRE Score', 'TOEFL Score', 'CGPA', 'University Rating'], outputCol='features')\n",
    "output_data = assembler.transform(df)\n",
    "output_data.show()\n",
    "final_data = output_data.select('features', 'Chance of Admit')\n",
    "scaler_model = scaler.fit(final_data)\n",
    "final_data = scaler_model.transform(final_data)\n",
    "final_data.show()\n",
    "\n",
    "# Split the dataset into training and testing data\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "#build the linear regression model\n",
    "lr = LinearRegression(featuresCol='scaledFeatures' ,labelCol='Chance of Admit')\n",
    "model = lr.fit(train_data)\n",
    "\n",
    "# Get coefficients and intercept\n",
    "print('Coefficients: {}'.format(model.coefficients))\n",
    "print('Intercept: {}'.format(model.intercept))\n",
    "\n",
    "# get summary of the model\n",
    "training_summary = model.summary\n",
    "print('RMSE: {}'.format(training_summary.rootMeanSquaredError))\n",
    "print('R2: {}'.format(training_summary.r2))\n",
    "\n",
    "# Transform the test data\n",
    "predictions = model.transform(test_data)\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.06494788804472544\n",
      "R2: 0.8045369387130764\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol='Chance of Admit', predictionCol='prediction', metricName='rmse')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "r2 = evaluator.evaluate(predictions, {evaluator.metricName: 'r2'})\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('R2: {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('linear_regression_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "# from pyspark.ml.regression import LinearRegressionModel\n",
    "# model = LinearRegressionModel.load('linear_regression_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
